{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4da7d79-4a5b-4711-a0d1-3b8ef1c8dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Union\n",
    "import requests # For URL validation\n",
    "\n",
    "# Langchain Imports\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader, WebBaseLoader, PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ae23f5-5503-4951-bf82-bc5ae0b3e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "083e78e7-0513-4bf1-aaaa-65da3115cd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized Groq LLM with model: meta-llama/llama-4-scout-17b-16e-instruct\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_MODEL_NAME = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "\n",
    "# Check if API key is set\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"GROQ_API_KEY not found in environment variables. Please set it in your .env file.\")\n",
    "\n",
    "# Initialize the Groq LLM\n",
    "try:\n",
    "    groq_llm = ChatGroq(\n",
    "        temperature=0,  # Lower temperature for more consistent summaries\n",
    "        groq_api_key=GROQ_API_KEY,\n",
    "        model_name=GROQ_MODEL_NAME\n",
    "    )\n",
    "    print(f\"Successfully initialized Groq LLM with model: {GROQ_MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Groq LLM: {e}\")\n",
    "    print(\"Please ensure your GROQ_API_KEY is correct and the model name is valid.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32a082e-0c25-4993-97d6-dab7209c6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Document Utilities (unchanged) ---\n",
    "def split_text_into_docs(text: str, chunk_size: int = 4000, chunk_overlap: int = 200) -> list[Document]:\n",
    "    \"\"\"Splits a long text string into a list of Langchain Document objects.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    docs = text_splitter.create_documents([text])\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0679e9-0cef-464e-b52d-1dd986a695b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs_from_url(url: str) -> Union[list[Document], None]: # <--- CHANGE MADE HERE\n",
    "    \"\"\"\n",
    "    Loads content from a URL into a list of Langchain Document objects.\n",
    "    Tries UnstructuredURLLoader first, falls back to WebBaseLoader.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to load content from URL: {url}\")\n",
    "    try:\n",
    "        # Basic check for URL validity\n",
    "        response = requests.head(url, allow_redirects=True, timeout=10)\n",
    "        response.raise_for_status() # Raise an exception for bad status codes\n",
    "\n",
    "        # Try UnstructuredURLLoader first for richer parsing\n",
    "        loader = UnstructuredURLLoader(urls=[url])\n",
    "        docs = loader.load()\n",
    "        if docs and docs[0].page_content.strip(): # Check if content is actually loaded\n",
    "            print(f\"Content loaded successfully from {url} using UnstructuredURLLoader.\")\n",
    "            return docs\n",
    "        else:\n",
    "            print(f\"UnstructuredURLLoader failed to get content or returned empty. Trying WebBaseLoader for {url}.\")\n",
    "            # Fallback to WebBaseLoader if UnstructuredURLLoader doesn't get content\n",
    "            loader = WebBaseLoader(url)\n",
    "            docs = loader.load()\n",
    "            if docs and docs[0].page_content.strip():\n",
    "                print(f\"Content loaded successfully from {url} using WebBaseLoader.\")\n",
    "                return docs\n",
    "            else:\n",
    "                print(f\"WebBaseLoader also failed to get content from {url}.\")\n",
    "                return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {url}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading URL {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abbe61a-3336-42ab-b2a0-39b1c430d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs_from_pdf(file_path: str) -> Union[list[Document], None]:\n",
    "    \"\"\"\n",
    "    Loads content from a PDF file into a list of Langchain Document objects.\n",
    "    Each page of the PDF becomes a separate Document.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to load content from PDF: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: PDF file not found at '{file_path}'\")\n",
    "        return None\n",
    "    if not file_path.lower().endswith(\".pdf\"):\n",
    "        print(f\"Error: Provided file '{file_path}' is not a PDF.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        # PyPDFLoader returns a list of Documents, where each Document is a page.\n",
    "        docs = loader.load()\n",
    "        if docs:\n",
    "            print(f\"Successfully loaded {len(docs)} pages from PDF.\")\n",
    "            return docs\n",
    "        else:\n",
    "            print(f\"No content extracted from PDF: {file_path}. It might be empty or unreadable.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading PDF file '{file_path}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a7d0577-2e1b-4f5a-a970-25c2260b87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summarization Function (Stuff Chain with verbose=True) ---\n",
    "def summarize_text_stuff(\n",
    "    input_content: str,\n",
    "    llm: ChatGroq,\n",
    "    prompt_template_str: str = None,\n",
    "    input_type: str = \"text\" # Added input_type parameter\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Summarizes text, URL, or PDF content using the Langchain 'stuff' chain with Groq.\n",
    "\n",
    "    Args:\n",
    "        input_content (str): The raw text, URL, or PDF file path to summarize.\n",
    "        llm (ChatGroq): The initialized Groq LLM instance.\n",
    "        prompt_template_str (str, optional): Custom prompt string.\n",
    "        input_type (str): 'text', 'url', or 'pdf' to indicate the type of input_content.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    docs_to_summarize = []\n",
    "\n",
    "    if input_type == \"url\":\n",
    "        docs = load_docs_from_url(input_content)\n",
    "        if not docs:\n",
    "            return \"Failed to load content from the provided URL.\"\n",
    "        combined_content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        docs_to_summarize = [Document(page_content=combined_content)]\n",
    "    elif input_type == \"pdf\":\n",
    "        docs = load_docs_from_pdf(input_content)\n",
    "        if not docs:\n",
    "            return \"Failed to load content from the provided PDF.\"\n",
    "        # For 'stuff' chain with PDF, combine all page contents into one large document\n",
    "        # as long as it fits the context window.\n",
    "        combined_content = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        docs_to_summarize = [Document(page_content=combined_content)]\n",
    "    elif input_type == \"text\":\n",
    "        docs_to_summarize = [Document(page_content=input_content)]\n",
    "    else:\n",
    "        return \"Invalid input_type specified. Must be 'text', 'url', or 'pdf'.\"\n",
    "\n",
    "\n",
    "    if not docs_to_summarize or not docs_to_summarize[0].page_content.strip():\n",
    "        return \"No valid content provided for summarization.\"\n",
    "\n",
    "    if prompt_template_str:\n",
    "        prompt = PromptTemplate(template=prompt_template_str, input_variables=[\"text\"])\n",
    "    else:\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are an expert summarizer. Provide a concise and comprehensive summary of the following text. Focus on the main points and key information.\n",
    "\n",
    "            Text:\n",
    "            \"{text}\"\n",
    "\n",
    "            Summary:\"\"\",\n",
    "            input_variables=[\"text\"]\n",
    "        )\n",
    "\n",
    "    print(f\"Using summarization prompt:\\n---\\n{prompt.template}\\n---\")\n",
    "\n",
    "    try:\n",
    "        chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt, verbose=True)\n",
    "        print(\"Invoking summarization chain...\")\n",
    "        summary = chain.invoke({\"input_documents\": docs_to_summarize})\n",
    "        return summary[\"output_text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during summarization: {e}\")\n",
    "        return f\"Error during summarization: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3569e05a-be1a-4286-aa26-d68e890d8864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Groq Text/URL/PDF Summarizer ---\n",
      "This tool can summarize text, web articles, or PDF documents using Groq's LLMs.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to summarize (T)ext, a (U)RL, or a (P)DF? (Type 'T', 'U', 'P', or 'Q' to quit):  P\n",
      "\n",
      "Please enter the path to the PDF file you want to summarize:  C:\\Users\\hp\\Downloads\\Seminar_Report.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarizing PDF: C:\\Users\\hp\\Downloads\\Seminar_Report.pdf...\n",
      "Attempting to load content from PDF: C:\\Users\\hp\\Downloads\\Seminar_Report.pdf\n",
      "Successfully loaded 8 pages from PDF.\n",
      "Using summarization prompt:\n",
      "---\n",
      "You are an expert summarizer. Provide a concise and comprehensive summary of the following text. Focus on the main points and key information.\n",
      "\n",
      "            Text:\n",
      "            \"{text}\"\n",
      "\n",
      "            Summary:\n",
      "---\n",
      "Invoking summarization chain...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an expert summarizer. Provide a concise and comprehensive summary of the following text. Focus on the main points and key information.\n",
      "\n",
      "            Text:\n",
      "            \"RESEARCH DOMAIN \n",
      " \n",
      "Introduction \n",
      " \n",
      "Data from different sources in geography, combined using deep learning, is driving major advances in \n",
      "remote sensing, urban planning, watching over the environment and disaster management. Using a \n",
      "variety of tools, including satellite images, LiDAR, GNSS, aerial images and ground-penetrating radar, \n",
      "researchers better understand the characteristics and changes of Earth’s surface. Because of recent \n",
      "progress in deep learning such as CNNs, RNNs and GANs, data fusion processes are now more \n",
      "accurate, reliable and can be used for a broader range of tasks. \n",
      " \n",
      "Key Approaches in Geospatial Data Fusion \n",
      " \n",
      "1. Fusion Levels and Strategies \n",
      "Deep learning-based data fusion methods operate at different levels: \n",
      "• Merging raw data from many sources during the earliest level of fusion helps improve \n",
      "both accuracy and robustness since it makes use of complementary details. \n",
      "• Feature-level fusion combines features taken from every input, resulting in \n",
      "representations that are complex and recognize relationships between various \n",
      "modalities. \n",
      "• Decision-level fusion amounts to mixing the results of models that used diverse data \n",
      "sources by means of majority voting or averaging weighted outputs. This kind of system \n",
      "tolerates errors but can miss some information. \n",
      "• Combining these ways in hybrid fusion results in better performance, mainly in complex \n",
      "cases such as spotting the origin of local fires or mapping geological structures. \n",
      "2. Deep Learning Architectures \n",
      "CNNs are commonly used to pull out important features from visual information and data \n",
      "organized over space. \n",
      "• Since RNN and their variations such as LSTM, are designed for time-related sequences, \n",
      "they stand out in predicting land use or environmental changes over time. \n",
      "• GANs have achieved good results in improving image quality and generating lifelike \n",
      "data; however, artifact problems still exist. \n",
      "• Predictive accuracy and robustness are improved even further by using hybrid models \n",
      "that blend the best aspects of several networks.\n",
      "\n",
      "Applications and Case Studies \n",
      " \n",
      "1. Land Cover and Urban Mapping \n",
      "Using studies such as Zhang et al. (2020) as an example, combining GNSS, satellite, aerial, LiDAR \n",
      "and GPR data through CNNs gives 90% or more accuracy for land cover classification and exceeds the \n",
      "accuracy of single-source models. The combination of detailed aerial images and accurate GNSS data \n",
      "sharpens urban planning and makes it easier to decide on infrastructure projects. \n",
      " \n",
      "2. Environmental Monitoring \n",
      "A group of deep learning models that work with spatial and time-related data have been used to observe \n",
      "and predict air quality, estimate solar irradiance and evaluate environmental risks. Patel et al. were able \n",
      "to make precise air quality predictions throu gh deep learning models and using AI -based anomaly \n",
      "detectors, it is now possible to track pollution in real-time and use synthetic sensors. \n",
      " \n",
      "3. 3D Geological Modeling \n",
      "Using both multipoint statistics and multimodal deep neural networks, recent work has helped to \n",
      "construct precise models of the geology that combine data from seismic, gravity, magnetic and \n",
      "topographic information. These models give important knowledge for  planning explorations and \n",
      "assessing risks. \n",
      " \n",
      "4. Disaster Management \n",
      "Despite difficulties understanding data from every source, algorithms developed for disaster \n",
      "management include live data streams from numerous systems to sharpen understanding and future \n",
      "predictions. \n",
      " \n",
      "Benefits and Synergies \n",
      "• By combining, multi-source fusion makes models both more accurate and stable since different \n",
      "data types cover different strengths. \n",
      "• Real-Time Processing is Possible: Even with high computational needs, better technology and \n",
      "algorithm optimization mean real-time functions can now be used more easily. \n",
      "• Increasing Scope of Use: Thanks to data fusion, data analysis is happening in urban planning, \n",
      "environmental monitoring, and disaster response.\n",
      "\n",
      "Challenges and Limitations \n",
      "• Database Demand: A lot of deep learning frames want lots of labeled data to work well, causing \n",
      "problems in areas with limited data. \n",
      "• Because of the high cost of running these networks, real-time applications and large-scale usage \n",
      "are difficult with multi-modal and high-resolution data. \n",
      "• There are technical problems in combining datasets that use different patterns of resolution, \n",
      "data types and noise. \n",
      "• Since interpretation is not always easy for hybrid and ensemble models, decision -makers may \n",
      "find it hard to use them in practical ways. \n",
      " \n",
      "Future Directions \n",
      "With these approaches, the need for massive labeled data is reduced. \n",
      "• Application of Algorithms and Hardware Design: Improving devices used in edge computing \n",
      "holds potential for quicker and better processing. \n",
      "• If data types and communication protocols are standard, integration of different datasets will \n",
      "happen more easily. \n",
      "• Improving noise resistance in algorithms and GAN artifact handling will strengthen the \n",
      "trustworthiness of the fused results. \n",
      "Take Aways \n",
      "• Deep learning is making the combination of multiple types of geospatial information possible \n",
      "which improves the value and detail of these insights. \n",
      "• Mixing spatial and temporal modelling with diverse types of data is expanding environmental \n",
      "controlling, city planning and managing disasters. \n",
      "• Solving problems such as data, speed and the interpretation of models will be necessary for \n",
      "wider use and significant results.\n",
      "\n",
      "RESEARCH PAPERS REFERRED DURING THE SEMESTER \n",
      " \n",
      " \n",
      "S.No. Author(s) Year Title \n",
      "1 Zhang et al. 2020 A Deep Learning Framework for Multi-\n",
      "Source Geospatial Data Fusion \n",
      "2 Liu et al. 2021 Multi-Modal Data Fusion Using LIDAR \n",
      "and Satellite Imagery \n",
      "3 Gupta et al. 2022 Enhancing Satellite Images with \n",
      "Generative Adversarial Networks \n",
      "4 Kim et al. 2023 Integrating GNSS and Aerial Imagery for \n",
      "Urban Planning \n",
      "5 Chen et al. 2023 Hybrid Model Combining CNNs and \n",
      "RNNs for Temporal Data Fusion \n",
      "6 Patel et al. 2021 Deep Learning for Environmental \n",
      "Monitoring \n",
      "7 Wang et al. 2022 Multi-Resolution Fusion of Satellite and \n",
      "Drone Imagery \n",
      "8 Smith et al. 2021 Integrating GPR Data with Imaging \n",
      "Techniques \n",
      "9 Johnson et \n",
      "al. 2020 Ensemble Learning Methods for \n",
      "Geospatial Data Fusion \n",
      "10 Lee et al. 2022 Machine Learning Algorithms for \n",
      "Disaster Management\n",
      "\n",
      "LITERATURE REVIEW OF THE RESEARCH PAPERS \n",
      "STUDIED \n",
      " \n",
      "1. Zhang et al. (2020) - A Deep Learning Framework for Multi -Source Geospatial Data \n",
      "Fusion \n",
      " \n",
      "The researchers created a strong deep learning architecture designed to combine diverse \n",
      "geospatial data and achieved accurate land cover classification with 92% accuracy using CNNs. The \n",
      "research underlines that making use of data from GNSS, satellite imagery, aerial photography, LiDAR, \n",
      "and GPR can help us learn more about the Earth's surface. One major roadblock is the need for vast \n",
      "amounts of labelled data, yet obtaining such data is not easy. They add that, while their approach \n",
      "enhances coherence and precision with the help of advanced AI, working with giant data sets might be \n",
      "difficult for current systems. \n",
      " \n",
      "Take Aways: \n",
      "• Strength: Shows how using many types of geospatial data leads to better unity across maps. \n",
      "• Issue: How well these systems work in places with little data is hindered by the need for \n",
      "substantial labelled datasets. \n",
      "• What’s Next: Future studies may prove that semi-supervised or transfer learning can help lessen \n",
      "the need for data. \n",
      " \n",
      "2. Liu et al. (2021) - Multi-Modal Data Fusion Using LiDAR and Satellite Imagery \n",
      "The team of Liu et al. merged LiDAR and satellite imagery data through a multi-modal method \n",
      "that provided a reported RMSE of 0.5 meters for elevations. Even though this method can substantially \n",
      "raise accuracy in geospatial areas, its demanding computations  make it more useful for non -real-time \n",
      "settings. They examine the technical issues related to working with large amounts of data and \n",
      "recommend that making improvements in computational fastness will help the  technique be applied \n",
      "more widely in urgent situations. \n",
      "  \n",
      "Take Aways: \n",
      "The program offers excellent detail when modelling the elevation of surfaces used for flood risk \n",
      "assessment. \n",
      "• Limitation: Computational demands restrict deployment in time-sensitive scenarios. \n",
      "• Improvements such as enhancing hardware or using low -complexity routines can make\n",
      "\n",
      "personal health devices easier to use. \n",
      " \n",
      "3. Gupta et al. (2022) - Enhancing Satellite Images with Generative Adversarial Networks \n",
      "According to Gupta et al., GANs applied to satellite imagery using new data merging methods \n",
      "work better, with an SSI of 0.85, than traditional practices that have an SSI of 0.75. The approach \n",
      "improves image quality, but how it works may not solve artifact issues in high-res images which can \n",
      "set back the quality of image enhancement. The authors propose modifying GAN models to help \n",
      "address these artifacts and strengthen the performance of satellite image upgrading. \n",
      " \n",
      "Take Aways: \n",
      "• Benefit: GANs may help in improving how images look when only a few pixels are available. \n",
      "• Limitations: Technology limited by artifacts makes applications used in military or disasters \n",
      "less trustworthy. \n",
      "• We may find that hybrid approaches (e.g., GANs and diffusion models) help reduce the \n",
      "problems causing those effects. \n",
      " \n",
      "4. Kim et al. (2023) - Integrating GNSS and Aerial Imagery for Urban Planning \n",
      "The authors use a study by Kim et al. to demonstrate that using GNSS data with aerial images \n",
      "in urban planning leads to a 15% higher accuracy than using conventional techniques. It demonstrates \n",
      "that using exact location information together with detailed p ictures helps improve choices in urban \n",
      "development. It is noted that linking various datasets is difficult due to the wide range of resolutions \n",
      "they have which could hinder the model performance. \n",
      " \n",
      "Take Aways: \n",
      "• Strength: Enhances decision-making for infrastructure development. \n",
      "• Limitation: Misalignment of multi-resolution data complicates model training. \n",
      "• Future Direction: Dynamic resolution-adjustment algorithms could improve integration. \n",
      " \n",
      "5. Chen et al. (2023) - Hybrid Model Combining CNNs and RNNs for Temporal Data Fusion \n",
      "The authors, Chen et al., present a type of network that integrates CNNs and RNNs for merging \n",
      "data in space and time. With this model, the team accurately predicted 90% of land use changes. Thanks \n",
      "to this innovation, CNNs are used to capture features in sp ace and RNNs are used to handle different \n",
      "moments in a sequence. Although this model presents promising results, it remains difficult to use and \n",
      "understand in real time, so simpler models that perform well are still needed.\n",
      "\n",
      "Take Aways: \n",
      "• Strength: Effective for spatiotemporal analysis (e.g., deforestation tracking). \n",
      "• Limitation: Model interpretability challenges hinder adoption in policy-making. \n",
      "• Attention mechanisms might soon make it much easier to identify important parts of data over \n",
      "time. \n",
      " \n",
      "6. Patel et al. (2021) - Deep Learning for Environmental Monitoring \n",
      "Air quality predictions made using Patel’s research showed an RMSE of 0.3 meters when using \n",
      "deep learning models. Although AI improves environmental assessments, the model operationalizes \n",
      "only if there are ongoing streams of data. The work points out that reliable data management is \n",
      "necessary to provide input for steady monitoring through software. \n",
      " \n",
      "Take Aways: \n",
      "• Useful: It supports monitoring air quality quickly in smart cities. \n",
      "• Limitation: Faulty sensors or missing data may lower the performance of the system. \n",
      "• Future Direction: Federated learning could decentralize data collection. \n",
      " \n",
      "7. Wang et al. (2022) - Multi-Resolution Fusion of Satellite and Drone Imagery \n",
      "The team combined satellite and drone images using a multi-resolution method which resulted \n",
      "in an SSI score of 0.9 for image quality assessments. Although this method improves how geospatial \n",
      "datasets are made, the authors believe that high computational ti mes are a main limitation that could \n",
      "hinder urgent projects that must be analyzed quickly. They suggest using different optimization \n",
      "methods to decrease processing time, even as quality stays high. \n",
      " \n",
      "Take Aways: \n",
      "• Strength: High-resolution outputs aid precision agriculture and forestry. \n",
      "• Processing time makes it hard to use satellites in fast-developing situations such as wildfires. \n",
      "• Future Direction: Edge computing could accelerate analysis. \n",
      " \n",
      "8. Smith et al. (2021) - Integrating GPR Data with Imaging Techniques \n",
      "The paper by Smith et al. explains how to combine GPR data with standard imaging techniques, \n",
      "leading to a mapping accuracy of 95% in underground applications. Even so, this technique leads to \n",
      "more reliable subsurface analysis, but major challenges such as limiting noise levels and efficient \n",
      "processing might prevent its use in complex situations.\n",
      "\n",
      "Take Aways: \n",
      "• Strength: Enables detailed underground utility mapping. \n",
      "• Limitation: Noise sensitivity reduces reliability in cluttered environments. \n",
      "• Future work may rely on algorithms that are not easily affected by noise. \n",
      " \n",
      "9. Johnson et al. (2020) - Ensemble Learning Methods for Geospatial Data Fusion \n",
      "In this research, Johnson uses various learning techniques together on geospatial data and finds \n",
      "that the overall accuracy improves by 10%, making the approach more robust. The study points out \n",
      "that running several different models allows to work with various kinds of data well, yet using them \n",
      "can be complex and challenging for most users. \n",
      "Take Aways: \n",
      "• Strength: Reduces overfitting in heterogeneous datasets. \n",
      "• Limitation: Complexity hampers adoption in resource-constrained settings. \n",
      "• In the future, automatic ways to select ensembles could save researcher’s time. \n",
      " \n",
      "10. Lee et al. (2022) - Machine Learning Algorithms for Disaster Management \n",
      "The team led by Lee examines various machine learning methods focused on disaster \n",
      "management and can predict accurately 88% of the time. It sheds light on how live data from several \n",
      "sources improves understanding of situations during disasters, but integrating that data requires fixing \n",
      "inconsistencies in the formats used. \n",
      "Take Aways: \n",
      "• Strength: Enhances real-time decision-making during disasters. \n",
      "• Limitation: Fragmented data formats hinder integration. \n",
      "• Future Direction: Standardized APIs could unify data pipelines.\"\n",
      "\n",
      "            Summary:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "--- Generated Summary ---\n",
      "**Summary of Deep Learning for Geospatial Data Fusion**\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "Deep learning techniques, such as CNNs, RNNs, and GANs, are driving advances in remote sensing, urban planning, environmental monitoring, and disaster management by fusing data from various sources, including satellite images, LiDAR, GNSS, aerial images, and ground-penetrating radar.\n",
      "\n",
      "**Key Approaches**\n",
      "\n",
      "1. **Fusion Levels and Strategies**: Data fusion occurs at different levels, including raw data, feature-level, decision-level, and hybrid fusion, each with its strengths and limitations.\n",
      "2. **Deep Learning Architectures**: CNNs, RNNs, GANs, and hybrid models are used for geospatial data fusion, with applications in land cover classification, environmental monitoring, and 3D geological modeling.\n",
      "\n",
      "**Applications and Case Studies**\n",
      "\n",
      "1. **Land Cover and Urban Mapping**: Fusing multi-source data with deep learning achieves high accuracy (>90%) for land cover classification and urban planning.\n",
      "2. **Environmental Monitoring**: Deep learning models predict air quality, estimate solar irradiance, and evaluate environmental risks with high accuracy.\n",
      "3. **3D Geological Modeling**: Multimodal deep neural networks construct precise geological models, providing valuable insights for exploration and risk assessment.\n",
      "4. **Disaster Management**: Deep learning algorithms integrate live data streams from multiple systems to improve understanding and predictions.\n",
      "\n",
      "**Benefits and Synergies**\n",
      "\n",
      "1. **Improved Accuracy and Stability**: Multi-source fusion enhances model accuracy and stability.\n",
      "2. **Real-Time Processing**: Advances in technology and algorithm optimization enable real-time processing.\n",
      "3. **Increased Scope of Use**: Data fusion expands applications in urban planning, environmental monitoring, and disaster response.\n",
      "\n",
      "**Challenges and Limitations**\n",
      "\n",
      "1. **Database Demand**: Deep learning requires large amounts of labeled data, which can be difficult to obtain.\n",
      "2. **Computational Cost**: High computational costs limit real-time applications and large-scale usage.\n",
      "3. **Technical Challenges**: Integrating datasets with different resolutions, data types, and noise levels is challenging.\n",
      "4. **Interpretability**: Hybrid and ensemble models can be difficult to interpret, hindering practical applications.\n",
      "\n",
      "**Future Directions**\n",
      "\n",
      "1. **Reducing Labeled Data Requirements**: Developing approaches that reduce the need for labeled data.\n",
      "2. **Improving Algorithm and Hardware Design**: Enhancing devices and algorithms for faster processing and better performance.\n",
      "3. **Standardizing Data Types and Communication Protocols**: Facilitating integration of different datasets.\n",
      "\n",
      "**Takeaways**\n",
      "\n",
      "1. Deep learning enables the combination of multiple types of geospatial information, improving insights and decision-making.\n",
      "2. Integrating spatial and temporal modeling with diverse data types expands environmental monitoring, urban planning, and disaster management.\n",
      "3. Addressing challenges such as data, speed, and model interpretability is crucial for wider adoption and significant results.\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Do you want to summarize (T)ext, a (U)RL, or a (P)DF? (Type 'T', 'U', 'P', or 'Q' to quit):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting summarizer. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# --- UPDATED Example Usage with User Input for Text, URL, or PDF ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Groq Text/URL/PDF Summarizer ---\")\n",
    "    print(\"This tool can summarize text, web articles, or PDF documents using Groq's LLMs.\")\n",
    "\n",
    "    while True:\n",
    "        user_input_type = input(\"\\nDo you want to summarize (T)ext, a (U)RL, or a (P)DF? (Type 'T', 'U', 'P', or 'Q' to quit): \").strip().upper()\n",
    "\n",
    "        if user_input_type == 'Q':\n",
    "            print(\"Exiting summarizer. Goodbye!\")\n",
    "            break\n",
    "        elif user_input_type == 'T':\n",
    "            print(\"\\nPlease paste the text you want to summarize. Press Enter twice when done (empty line).\")\n",
    "            lines = []\n",
    "            while True:\n",
    "                line = input()\n",
    "                if not line:\n",
    "                    break\n",
    "                lines.append(line)\n",
    "            content_to_summarize = \"\\n\".join(lines)\n",
    "\n",
    "            if not content_to_summarize.strip():\n",
    "                print(\"No text provided. Please try again.\")\n",
    "                continue\n",
    "\n",
    "            print(\"\\nSummarizing text...\")\n",
    "            summary = summarize_text_stuff(content_to_summarize, groq_llm, input_type=\"text\")\n",
    "            print(\"\\n--- Generated Summary ---\")\n",
    "            print(summary)\n",
    "            print(\"-------------------------\")\n",
    "\n",
    "        elif user_input_type == 'U':\n",
    "            content_to_summarize = input(\"\\nPlease enter the URL of the article you want to summarize: \").strip()\n",
    "\n",
    "            if not (content_to_summarize.startswith(\"http://\") or content_to_summarize.startswith(\"https://\")):\n",
    "                print(\"Invalid URL format. Please ensure it starts with 'http://' or 'https://'.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nSummarizing URL: {content_to_summarize}...\")\n",
    "            summary = summarize_text_stuff(content_to_summarize, groq_llm, input_type=\"url\")\n",
    "            print(\"\\n--- Generated Summary ---\")\n",
    "            print(summary)\n",
    "            print(\"-------------------------\")\n",
    "\n",
    "        elif user_input_type == 'P':\n",
    "            pdf_file_path = input(\"\\nPlease enter the path to the PDF file you want to summarize: \").strip()\n",
    "\n",
    "            if not pdf_file_path:\n",
    "                print(\"No file path provided. Please try again.\")\n",
    "                continue\n",
    "            if not os.path.exists(pdf_file_path):\n",
    "                print(f\"Error: File not found at '{pdf_file_path}'. Please check the path.\")\n",
    "                continue\n",
    "            if not pdf_file_path.lower().endswith(\".pdf\"):\n",
    "                print(f\"Error: The file '{pdf_file_path}' does not appear to be a PDF.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"\\nSummarizing PDF: {pdf_file_path}...\")\n",
    "            summary = summarize_text_stuff(pdf_file_path, groq_llm, input_type=\"pdf\")\n",
    "            print(\"\\n--- Generated Summary ---\")\n",
    "            print(summary)\n",
    "            print(\"-------------------------\")\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter 'T' for Text, 'U' for URL, 'P' for PDF, or 'Q' to quit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
